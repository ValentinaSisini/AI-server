# AI-server
Questo repository raccoglie tutti i passaggi del percorso che abbiamo seguito per portare un modello LLM a funzionare su un server: dall’installazione dell’ambiente alla configurazione del modello, fino ai test di inferenza e ottimizzazione delle prestazioni.
Non è solo una guida tecnica, ma anche il racconto del lavoro fatto passo dopo passo, con script, note e risultati che mostrano come il progetto è cresciuto fino a diventare operativo.
